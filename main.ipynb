{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7776664,"sourceType":"datasetVersion","datasetId":4550340}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lightning","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r-7W-4mBw_bS","outputId":"5cf3340b-4846-4e60-d6f2-02502054b9de","execution":{"iopub.status.busy":"2024-03-06T16:14:17.571048Z","iopub.execute_input":"2024-03-06T16:14:17.571434Z","iopub.status.idle":"2024-03-06T16:14:30.569715Z","shell.execute_reply.started":"2024-03-06T16:14:17.571404Z","shell.execute_reply":"2024-03-06T16:14:30.568720Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: lightning in /opt/conda/lib/python3.10/site-packages (2.2.1)\nRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\nRequirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.0)\nRequirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.10.1)\nRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.4)\nRequirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\nRequirement already satisfied: torch<4.0,>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.3.1)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.1)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.9.0)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.0.post0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (69.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.6)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom transformers import DistilBertModel, DistilBertTokenizer\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport lightning as L\nimport torch.nn as nn\nimport csv","metadata":{"id":"pGDh_wu71hlg","execution":{"iopub.status.busy":"2024-03-06T16:14:30.572440Z","iopub.execute_input":"2024-03-06T16:14:30.573437Z","iopub.status.idle":"2024-03-06T16:14:36.441028Z","shell.execute_reply.started":"2024-03-06T16:14:30.573377Z","shell.execute_reply":"2024-03-06T16:14:36.440027Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"id":"55SzB6oV1hli","execution":{"iopub.status.busy":"2024-03-06T16:14:36.442285Z","iopub.execute_input":"2024-03-06T16:14:36.442724Z","iopub.status.idle":"2024-03-06T16:14:36.448160Z","shell.execute_reply.started":"2024-03-06T16:14:36.442696Z","shell.execute_reply":"2024-03-06T16:14:36.447164Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!unzip \"/content/archive_27.zip\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPL_Hrl704zb","outputId":"bf40366d-1e3c-4fdc-d8b7-3338181e3d5e","execution":{"iopub.status.busy":"2024-03-06T16:14:36.449221Z","iopub.execute_input":"2024-03-06T16:14:36.449528Z","iopub.status.idle":"2024-03-06T16:14:37.402906Z","shell.execute_reply.started":"2024-03-06T16:14:36.449504Z","shell.execute_reply":"2024-03-06T16:14:37.401913Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"unzip:  cannot find or open /content/archive_27.zip, /content/archive_27.zip.zip or /content/archive_27.zip.ZIP.\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/mbtidata/mbti_1.csv\")","metadata":{"id":"wEq7AXUK5yfC","colab":{"base_uri":"https://localhost:8080/","height":304},"outputId":"f92e403d-ed31-42af-a1c7-6babb3d0a201","execution":{"iopub.status.busy":"2024-03-06T16:14:37.406917Z","iopub.execute_input":"2024-03-06T16:14:37.407656Z","iopub.status.idle":"2024-03-06T16:14:38.149580Z","shell.execute_reply.started":"2024-03-06T16:14:37.407615Z","shell.execute_reply":"2024-03-06T16:14:38.148772Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"id":"esIZnYOb1hli","execution":{"iopub.status.busy":"2024-03-06T16:14:38.150762Z","iopub.execute_input":"2024-03-06T16:14:38.151140Z","iopub.status.idle":"2024-03-06T16:14:38.167040Z","shell.execute_reply.started":"2024-03-06T16:14:38.151089Z","shell.execute_reply":"2024-03-06T16:14:38.166041Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"      type                                              posts\n0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n1     ENTP  'I'm finding the lack of me in these posts ver...\n2     INTP  'Good one  _____   https://www.youtube.com/wat...\n3     INTJ  'Dear INTP,   I enjoyed our conversation the o...\n4     ENTJ  'You're fired.|||That's another silly misconce...\n...    ...                                                ...\n8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...\n8671  ENFP  'So...if this thread already exists someplace ...\n8672  INTP  'So many questions when i do these things.  I ...\n8673  INFP  'I am very conflicted right now when it comes ...\n8674  INFP  'It has been too long since I have been on per...\n\n[8675 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>posts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTP</td>\n      <td>'I'm finding the lack of me in these posts ver...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INTP</td>\n      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTJ</td>\n      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTJ</td>\n      <td>'You're fired.|||That's another silly misconce...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8670</th>\n      <td>ISFP</td>\n      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n    </tr>\n    <tr>\n      <th>8671</th>\n      <td>ENFP</td>\n      <td>'So...if this thread already exists someplace ...</td>\n    </tr>\n    <tr>\n      <th>8672</th>\n      <td>INTP</td>\n      <td>'So many questions when i do these things.  I ...</td>\n    </tr>\n    <tr>\n      <th>8673</th>\n      <td>INFP</td>\n      <td>'I am very conflicted right now when it comes ...</td>\n    </tr>\n    <tr>\n      <th>8674</th>\n      <td>INFP</td>\n      <td>'It has been too long since I have been on per...</td>\n    </tr>\n  </tbody>\n</table>\n<p>8675 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"encode_dict = {}\n\ndef encode_cat(x):\n    if x not in encode_dict.keys():\n        encode_dict[x]=len(encode_dict)\n    return encode_dict[x]\n\ndata['ENCODE_CAT'] = data['type'].apply(lambda x: encode_cat(x))","metadata":{"id":"-owKpYgOIq_4","execution":{"iopub.status.busy":"2024-03-06T16:14:38.168055Z","iopub.execute_input":"2024-03-06T16:14:38.168351Z","iopub.status.idle":"2024-03-06T16:14:38.183284Z","shell.execute_reply.started":"2024-03-06T16:14:38.168328Z","shell.execute_reply":"2024-03-06T16:14:38.182252Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"id":"6HgTdSVPI2d4","execution":{"iopub.status.busy":"2024-03-06T16:14:38.184586Z","iopub.execute_input":"2024-03-06T16:14:38.185482Z","iopub.status.idle":"2024-03-06T16:14:38.203075Z","shell.execute_reply.started":"2024-03-06T16:14:38.185443Z","shell.execute_reply":"2024-03-06T16:14:38.202175Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"      type                                              posts  ENCODE_CAT\n0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...           0\n1     ENTP  'I'm finding the lack of me in these posts ver...           1\n2     INTP  'Good one  _____   https://www.youtube.com/wat...           2\n3     INTJ  'Dear INTP,   I enjoyed our conversation the o...           3\n4     ENTJ  'You're fired.|||That's another silly misconce...           4\n...    ...                                                ...         ...\n8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...           8\n8671  ENFP  'So...if this thread already exists someplace ...           7\n8672  INTP  'So many questions when i do these things.  I ...           2\n8673  INFP  'I am very conflicted right now when it comes ...           6\n8674  INFP  'It has been too long since I have been on per...           6\n\n[8675 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>posts</th>\n      <th>ENCODE_CAT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTP</td>\n      <td>'I'm finding the lack of me in these posts ver...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INTP</td>\n      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTJ</td>\n      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTJ</td>\n      <td>'You're fired.|||That's another silly misconce...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8670</th>\n      <td>ISFP</td>\n      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8671</th>\n      <td>ENFP</td>\n      <td>'So...if this thread already exists someplace ...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8672</th>\n      <td>INTP</td>\n      <td>'So many questions when i do these things.  I ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8673</th>\n      <td>INFP</td>\n      <td>'I am very conflicted right now when it comes ...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8674</th>\n      <td>INFP</td>\n      <td>'It has been too long since I have been on per...</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>8675 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')","metadata":{"id":"DAO6J87F1hlj","execution":{"iopub.status.busy":"2024-03-06T16:14:38.204361Z","iopub.execute_input":"2024-03-06T16:14:38.204676Z","iopub.status.idle":"2024-03-06T16:14:38.624146Z","shell.execute_reply.started":"2024-03-06T16:14:38.204647Z","shell.execute_reply":"2024-03-06T16:14:38.623160Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nLabelEncoder().fit_transform(data['type'])","metadata":{"id":"yze6KOuP1hlj","execution":{"iopub.status.busy":"2024-03-06T16:14:38.625259Z","iopub.execute_input":"2024-03-06T16:14:38.625550Z","iopub.status.idle":"2024-03-06T16:14:39.108779Z","shell.execute_reply.started":"2024-03-06T16:14:38.625526Z","shell.execute_reply":"2024-03-06T16:14:39.107865Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array([ 8,  3, 11, ..., 11,  9,  9])"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import random_split","metadata":{"id":"N74gGcFKFiQq","execution":{"iopub.status.busy":"2024-03-06T16:14:39.109800Z","iopub.execute_input":"2024-03-06T16:14:39.110266Z","iopub.status.idle":"2024-03-06T16:14:39.114612Z","shell.execute_reply.started":"2024-03-06T16:14:39.110240Z","shell.execute_reply":"2024-03-06T16:14:39.113566Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class MBTIdataset(Dataset):\n    def __init__(self, data, tokenizer, max_len):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __getitem__(self, index):\n        post = self.data.posts[index]\n        inputs = self.tokenizer.encode_plus(text=post,max_length=self.max_len,truncation=True, pad_to_max_length=True, return_token_type_ids=True)\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n\n        return {\n            'ids': torch.tensor(ids,dtype=torch.long),\n            'mask': torch.tensor(mask,dtype=torch.long),\n            'targets': torch.tensor(self.data.ENCODE_CAT[index], dtype=torch.long)\n\n        }\n\n    def __len__(self):\n        return len(self.data)\n\ntrain_size = int(0.8 * len(data))\nval_size = len(data) - train_size\n\ndataset = MBTIdataset(data,tokenizer,512)\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=False,num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False,num_workers=0)","metadata":{"id":"MoJETG6W1hlj","execution":{"iopub.status.busy":"2024-03-06T16:14:39.116014Z","iopub.execute_input":"2024-03-06T16:14:39.116408Z","iopub.status.idle":"2024-03-06T16:14:39.127943Z","shell.execute_reply.started":"2024-03-06T16:14:39.116366Z","shell.execute_reply":"2024-03-06T16:14:39.127025Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')","metadata":{"id":"opNjsA46y7Y-","execution":{"iopub.status.busy":"2024-03-06T16:14:39.129170Z","iopub.execute_input":"2024-03-06T16:14:39.129503Z","iopub.status.idle":"2024-03-06T16:14:39.291809Z","shell.execute_reply.started":"2024-03-06T16:14:39.129468Z","shell.execute_reply":"2024-03-06T16:14:39.290830Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport torchmetrics","metadata":{"id":"u2SAYiDQ1hlk","execution":{"iopub.status.busy":"2024-03-06T16:14:39.295827Z","iopub.execute_input":"2024-03-06T16:14:39.296150Z","iopub.status.idle":"2024-03-06T16:14:39.319535Z","shell.execute_reply.started":"2024-03-06T16:14:39.296123Z","shell.execute_reply":"2024-03-06T16:14:39.318632Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class Model(L.LightningModule):\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n        self.pre_classifier = nn.Linear(768,768)\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(768,16)\n        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=16)\n        self.f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=16)\n\n    def forward(self,input_ids, attention_mask):\n        out_1 = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_state = out_1[0]\n        pooler = hidden_state[:,0]\n        pooler = self.pre_classifier(pooler)\n        pooler = nn.ReLU()(pooler)\n        pooler = self.dropout(pooler)\n        output = self.classifier(pooler)\n        return output\n\n    def training_step(self, batch, batch_idx):\n        item = batch\n        ids = item['ids']\n        mask = item['mask']\n        targets = item['targets']\n        outputs = self(ids, mask)\n        loss = torch.nn.CrossEntropyLoss()(outputs, targets)\n        accuracy = self.accuracy(outputs, targets)\n        f1_score = self.f1_score(outputs, targets)\n        self.log_dict({'train_loss':loss,'train_accuracy':accuracy,'train_f1_score':f1_score},on_epoch=True,prog_bar=True)\n\n        return loss\n\n    def validation_step(self,batch,batch_idx):\n      item = batch\n      ids = item['ids']\n      mask = item['mask']\n      targets = item['targets']\n      outputs = self(ids, mask)\n      loss = torch.nn.CrossEntropyLoss()(outputs, targets)\n      self.log('val_loss',loss)\n\n      return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=1e-5)\n","metadata":{"id":"p7kA04Nt1hlk","execution":{"iopub.status.busy":"2024-03-06T16:14:39.320669Z","iopub.execute_input":"2024-03-06T16:14:39.320948Z","iopub.status.idle":"2024-03-06T16:14:39.333872Z","shell.execute_reply.started":"2024-03-06T16:14:39.320924Z","shell.execute_reply":"2024-03-06T16:14:39.332986Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"next(iter(train_loader))","metadata":{"id":"6vZQ-gmJG9Ks","execution":{"iopub.status.busy":"2024-03-06T16:14:39.334866Z","iopub.execute_input":"2024-03-06T16:14:39.335104Z","iopub.status.idle":"2024-03-06T16:14:40.600897Z","shell.execute_reply.started":"2024-03-06T16:14:39.335084Z","shell.execute_reply":"2024-03-06T16:14:40.599931Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'ids': tensor([[  101,   112,  4514,  ...,  1547,  1136,   102],\n         [  101,   112,   146,  ..., 21155, 11776,   102],\n         [  101,   112,  2066,  ...,   119,   119,   102],\n         ...,\n         [  101,  2009,  1132,  ...,   119,   119,   102],\n         [  101,   112,  7277,  ...,  9020, 15969,   102],\n         [  101,   112,   113,  ...,   117,  1105,   102]]),\n 'mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1],\n         ...,\n         [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1]]),\n 'targets': tensor([ 7,  0,  2,  0,  6,  5,  6,  2,  8,  0,  6,  0,  6, 13,  2,  6,  7,  3,\n          3, 10,  2, 11,  2,  2,  2,  0,  0,  7,  6,  8,  5,  0])}"},"metadata":{}}]},{"cell_type":"code","source":"import wandb\nfrom pytorch_lightning.loggers import WandbLogger","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:14:40.602564Z","iopub.execute_input":"2024-03-06T16:14:40.602849Z","iopub.status.idle":"2024-03-06T16:14:41.035594Z","shell.execute_reply.started":"2024-03-06T16:14:40.602813Z","shell.execute_reply":"2024-03-06T16:14:41.034827Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"wandb_logger = WandbLogger(project='my-awesome-project')","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:14:41.036758Z","iopub.execute_input":"2024-03-06T16:14:41.037028Z","iopub.status.idle":"2024-03-06T16:14:41.108257Z","shell.execute_reply.started":"2024-03-06T16:14:41.037006Z","shell.execute_reply":"2024-03-06T16:14:41.107498Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model = Model()\ntrainer = L.Trainer(logger=wandb_logger, max_epochs=10)\ntrainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)","metadata":{"id":"6dbifPks8cwO","execution":{"iopub.status.busy":"2024-03-06T16:14:41.109402Z","iopub.execute_input":"2024-03-06T16:14:41.109684Z","iopub.status.idle":"2024-03-06T17:41:04.988827Z","shell.execute_reply.started":"2024-03-06T16:14:41.109660Z","shell.execute_reply":"2024-03-06T17:41:04.987533Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mameen-91\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>./wandb/run-20240306_161444-cg9ss381</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ameen-91/my-awesome-project/runs/cg9ss381' target=\"_blank\">upbeat-puddle-5</a></strong> to <a href='https://wandb.ai/ameen-91/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ameen-91/my-awesome-project' target=\"_blank\">https://wandb.ai/ameen-91/my-awesome-project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ameen-91/my-awesome-project/runs/cg9ss381' target=\"_blank\">https://wandb.ai/ameen-91/my-awesome-project/runs/cg9ss381</a>"},"metadata":{}},{"name":"stderr","text":"INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\nINFO: \n  | Name           | Type               | Params\n------------------------------------------------------\n0 | bert           | DistilBertModel    | 66.4 M\n1 | pre_classifier | Linear             | 590 K \n2 | dropout        | Dropout            | 0     \n3 | classifier     | Linear             | 12.3 K\n4 | accuracy       | MulticlassAccuracy | 0     \n5 | f1_score       | MulticlassF1Score  | 0     \n------------------------------------------------------\n67.0 M    Trainable params\n0         Non-trainable params\n67.0 M    Total params\n267.863   Total estimated model params size (MB)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17d388941e124fd0b0263f916c002182"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eded5c430db84bd4b26e4a754bbab9ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0cf683441d94979bc12c2a744795dbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ba67c0571d74a8d8761d85525238a75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39137943c2d1473e80c9fa58c4aad46d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"649cff61e6c643a5ac285b7d43c134b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"769be0ad814b4926815cbaf60f8d47be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8608e110a7944b6aa0bf83453089f39e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aed01f21d7ae43d88f9800d01d954e3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acb7d72c543d4d6989753660cb6afe1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23c0cfb1e3384145a594f03ebe72afd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6fd7c459df7473f9e38bec12ecc5be3"}},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T17:41:04.990252Z","iopub.execute_input":"2024-03-06T17:41:04.990539Z","iopub.status.idle":"2024-03-06T17:41:08.825189Z","shell.execute_reply.started":"2024-03-06T17:41:04.990512Z","shell.execute_reply":"2024-03-06T17:41:08.824288Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24ae984cafaf49af9149f9d46bfec315"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train_accuracy_epoch</td><td>▁▂▄▄▅▆▇▇██</td></tr><tr><td>train_accuracy_step</td><td>▂▂▁▂▂▃▂▄▄▄▃▄▆▄▅▅▅▅▄▄▆▆▆▆▆█▆▇▇▇▇▆▇▇▇▇███▇</td></tr><tr><td>train_f1_score_epoch</td><td>▁▂▄▄▅▆▇▇██</td></tr><tr><td>train_f1_score_step</td><td>▂▂▁▂▂▃▂▄▄▄▃▄▆▄▅▅▅▅▄▄▆▆▆▆▆█▆▇▇▇▇▆▇▇▇▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▅▄▄▃▂▂▁</td></tr><tr><td>train_loss_step</td><td>███▇█▇▇▇▆▆▆▅▄▆▆▅▅▄▅▆▄▅▄▅▄▂▄▃▃▂▂▄▂▂▂▃▂▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▄▁▁▁▁▂▃▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy_epoch</td><td>0.84899</td></tr><tr><td>train_accuracy_step</td><td>0.84375</td></tr><tr><td>train_f1_score_epoch</td><td>0.84899</td></tr><tr><td>train_f1_score_step</td><td>0.84375</td></tr><tr><td>train_loss_epoch</td><td>0.62346</td></tr><tr><td>train_loss_step</td><td>0.49634</td></tr><tr><td>trainer/global_step</td><td>2169</td></tr><tr><td>val_loss</td><td>2.11936</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">upbeat-puddle-5</strong> at: <a href='https://wandb.ai/ameen-91/my-awesome-project/runs/cg9ss381' target=\"_blank\">https://wandb.ai/ameen-91/my-awesome-project/runs/cg9ss381</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240306_161444-cg9ss381/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"bPJfJ3CFKyou","execution":{"iopub.status.busy":"2024-03-06T17:41:08.826411Z","iopub.execute_input":"2024-03-06T17:41:08.826657Z","iopub.status.idle":"2024-03-06T17:41:08.832874Z","shell.execute_reply.started":"2024-03-06T17:41:08.826635Z","shell.execute_reply":"2024-03-06T17:41:08.831912Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Saving the files for re-use\n\noutput_model_file = './pytorch_distilbert_mbti.bin'\noutput_vocab_file = './vocab_distilbert_mbti.bin'\n\nmodel_to_save = model\ntorch.save(model_to_save, output_model_file)\ntokenizer.save_vocabulary(output_vocab_file)\n\nprint('All files saved')\nprint('This tutorial is completed')","metadata":{"id":"IRxc7DoKI-Cf","execution":{"iopub.status.busy":"2024-03-06T17:41:08.834222Z","iopub.execute_input":"2024-03-06T17:41:08.834562Z","iopub.status.idle":"2024-03-06T17:41:09.325725Z","shell.execute_reply.started":"2024-03-06T17:41:08.834531Z","shell.execute_reply":"2024-03-06T17:41:09.324626Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"All files saved\nThis tutorial is completed\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2024-03-06T17:49:19.929335Z","iopub.execute_input":"2024-03-06T17:49:19.930151Z","iopub.status.idle":"2024-03-06T17:49:19.936410Z","shell.execute_reply.started":"2024-03-06T17:49:19.930117Z","shell.execute_reply":"2024-03-06T17:49:19.935382Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink \nFileLink(r'pytorch_distilbert_mbti.bin')","metadata":{"execution":{"iopub.status.busy":"2024-03-06T17:50:35.963182Z","iopub.execute_input":"2024-03-06T17:50:35.963549Z","iopub.status.idle":"2024-03-06T17:50:35.970193Z","shell.execute_reply.started":"2024-03-06T17:50:35.963523Z","shell.execute_reply":"2024-03-06T17:50:35.969174Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/pytorch_distilbert_mbti.bin","text/html":"<a href='pytorch_distilbert_mbti.bin' target='_blank'>pytorch_distilbert_mbti.bin</a><br>"},"metadata":{}}]}]}